import requests
from bs4 import BeautifulSoup
import urllib.parse
import re
import statistics
import os
import random
from datetime import datetime

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                  "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def get_soup(url):
    try:
        resp = requests.get(url, headers=HEADERS)
        if resp.status_code != 200:
            print(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏: {resp.status_code}")
            return None
        return BeautifulSoup(resp.text, "html.parser")
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Ç—É: {e}")
        return None

def get_prices_and_links_from_url(url, pages=3, min_price=None, max_price=None):
    all_prices = []
    all_links = []
    for page in range(1, pages + 1):
        page_url = f"{url}?page={page}"
        print(f"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—é —Å—Ç–æ—Ä—ñ–Ω–∫—É {page}...")
        soup = get_soup(page_url)
        if not soup:
            break
        listings = soup.select("div[data-testid='listing-grid'] div[data-cy='l-card']")
        if not listings:
            print("–û–≥–æ–ª–æ—à–µ–Ω—å –±—ñ–ª—å—à–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            break

        for listing in listings:
            price_tag = listing.select_one("p[data-testid='ad-price']")
            link_tag = listing.find("a", href=True)
            if not price_tag or not link_tag:
                continue
            price_text = price_tag.get_text(strip=True)
            match = re.search(r"(\d[\d\s]*)", price_text.replace('\xa0', ' '))
            if match:
                price = int(match.group(1).replace(" ", ""))
                if (min_price is not None and price < min_price) or (max_price is not None and price > max_price):
                    continue
                link = "https://www.olx.ua" + link_tag['href'].split('#')[0]
                all_prices.append(price)
                all_links.append(link)

    return all_prices, all_links

def show_stats(prices):
    if not prices:
        print("–¶—ñ–Ω–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return None
    min_price = min(prices)
    max_price = max(prices)
    avg_price = round(statistics.mean(prices), 2)
    print(f"\n–ó–Ω–∞–π–¥–µ–Ω–æ {len(prices)} —Ü—ñ–Ω:")
    print(f"–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Ü—ñ–Ω–∞: {min_price} –≥—Ä–Ω")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —Ü—ñ–Ω–∞: {max_price} –≥—Ä–Ω")
    print(f"–°–µ—Ä–µ–¥–Ω—è —Ü—ñ–Ω–∞: {avg_price} –≥—Ä–Ω")
    return avg_price, min_price, max_price

def save_results(subdir, filename, prices, links):
    script_dir = os.path.dirname(os.path.abspath(__file__))
    directory = os.path.join(script_dir, subdir)
    os.makedirs(directory, exist_ok=True)
    path = os.path.join(directory, filename)
    with open(path, "w", encoding="utf-8") as f:
        for price, link in zip(prices, links):
            f.write(f"{price} –≥—Ä–Ω | {link}\n")
    print(f"–ó–±–µ—Ä–µ–∂–µ–Ω–æ {len(prices)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É {path}")

def print_results(prices, links):
    print("\n–û–≥–æ–ª–æ—à–µ–Ω–Ω—è:")
    for i, (price, link) in enumerate(zip(prices, links), 1):
        print(f"{i}. {price} –≥—Ä–Ω | {link}")

def input_price(prompt):
    while True:
        val = input(prompt).strip()
        if val == "":
            return None
        if val.isdigit():
            return int(val)
        print("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å —á–∏—Å–ª–æ –∞–±–æ –∑–∞–ª–∏—à—Ç–µ –ø–æ—Ä–æ–∂–Ω—ñ–º.")

def main():
    query = input("üîç –í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç –¥–ª—è –ø–æ—à—É–∫—É –Ω–∞ OLX (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: iPhone 12): ").strip()
    if not query:
        print("–ü–æ—Ä–æ–∂–Ω—ñ–π –∑–∞–ø–∏—Ç. –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è.")
        return

    encoded_query = urllib.parse.quote(query)
    search_url = f"https://www.olx.ua/uk/list/q-{encoded_query}/"

    prices, links = get_prices_and_links_from_url(search_url, pages=3)
    if not prices:
        print("–ù—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    safe_query = re.sub(r"[^\w\d_-]", "_", query.lower())

    save_results("presearch", f"{safe_query}__{timestamp}.txt", prices, links)

    combined = list(zip(prices, links))
    if len(combined) > 20:
        combined = random.sample(combined, 20)
    sel_prices = [p for p, _ in combined]
    sel_links = [l for _, l in combined]

    show_stats(sel_prices)
    print_results(sel_prices, sel_links)

    while True:
        filter_answer = input("\n–ë–∞–∂–∞—î—Ç–µ –∑–∞–¥–∞—Ç–∏ —Ñ—ñ–ª—å—Ç—Ä —Ü—ñ–Ω–∏? (—Ç–∞–∫/y/yes/–Ω—ñ/n/no): ").strip().lower()
        if filter_answer in ("—Ç–∞–∫", "y", "yes"):
            min_price = input_price("–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Ü—ñ–Ω–∞ (Enter —â–æ–± –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏): ")
            max_price = input_price("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —Ü—ñ–Ω–∞ (Enter —â–æ–± –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏): ")
            prices_f, links_f = get_prices_and_links_from_url(search_url, pages=3, min_price=min_price, max_price=max_price)
            if not prices_f:
                print("–û–≥–æ–ª–æ—à–µ–Ω—å —É –∑–∞–¥–∞–Ω–æ–º—É –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
                continue

            combined_f = list(zip(prices_f, links_f))
            if len(combined_f) > 20:
                combined_f = random.sample(combined_f, 20)
            sel_prices_f = [p for p, _ in combined_f]
            sel_links_f = [l for _, l in combined_f]

            show_stats(sel_prices_f)
            print_results(sel_prices_f, sel_links_f)
            save_results("results", f"{safe_query}__filtered__{timestamp}.txt", sel_prices_f, sel_links_f)
            break

        elif filter_answer in ("–Ω—ñ", "n", "no"):
            print("–§—ñ–ª—å—Ç—Ä –Ω–µ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ.")
            save_results("results", f"{safe_query}__{timestamp}.txt", sel_prices, sel_links)
            break
        else:
            print("–í—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–∞. –í–≤–µ–¥—ñ—Ç—å —Ç–∞–∫ –∞–±–æ –Ω—ñ.")

if __name__ == "__main__":
    main()
